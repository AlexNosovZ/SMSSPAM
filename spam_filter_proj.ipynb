{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Загрузка данных + импорты"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Импорты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "#импорты\n",
    "#from nltk.tokenize import word_tokenize, RegexpTokenizer\n",
    "#from nltk.corpus import stopwords\n",
    "from sklearn.model_selection import train_test_split, cross_validate\n",
    "import pandas as pd\n",
    "from sklearn.naive_bayes import ComplementNB\n",
    "#from sklearn.metrics import accuracy_score,f1_score, precision_score, recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "from scipy.stats import ttest_ind\n",
    "from scipy import stats as st\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILESOURCE = 'SMSSpamCollection.txt' # файл источник\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Чтение файла"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ham\tGo until jurong \n"
     ]
    }
   ],
   "source": [
    "# читаем файл\n",
    "with open(FILESOURCE) as f: \n",
    "    full_file = f.read()\n",
    "print(full_file[:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Вывод:** данные удалось прочитать, уже неплохо"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Предобработка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "# нижний регистр и разделение на строки.\n",
    "full_file = full_file.lower()\n",
    "lst = full_file.splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Отделение таргета\n",
    "lst_with_target = []\n",
    "for line in lst:\n",
    "    lst_tmp = []\n",
    "    lst_line = line.split('\\t')  \n",
    "    if lst_line[0] == 'spam' or lst_line[0] == 'ham':\n",
    "        lst_tmp.append('ok')\n",
    "        lst_tmp.append(lst_line[0])\n",
    "        lst_tmp.append(lst_line[1:])\n",
    "        lst_with_target.append(lst_tmp)\n",
    "    else:\n",
    "        lst_tmp.append('not_ok')\n",
    "        lst_tmp.append(lst_line[0])\n",
    "        lst_tmp.append(lst_line[1:])\n",
    "        lst_with_target.append(lst_tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "# проверка на структуру файла\n",
    "for i in range(len(lst_with_target)):\n",
    "    if lst_with_target[i][0] != 'ok':\n",
    "        print(lst_with_target[i], 'is not ok')\n",
    "    if len(lst_with_target[i]) > 3:\n",
    "        print(lst_with_target[i], '>3')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Вывод:** структура файла соблюдается"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(stop_words='english', token_pattern='[a-z]\\w+')\n",
    "X = vectorizer.fit_transform(lst)\n",
    "#vectorizer.get_feature_names_out()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer2 = CountVectorizer(token_pattern='[0-9]\\w+')\n",
    "X2 = vectorizer2.fit_transform(lst)\n",
    "vectorizer3 = CountVectorizer(token_pattern='[§!@#$%^&*()_+-<>:\"|\\?~{}]')\n",
    "X3 = vectorizer3.fit_transform(lst)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(X.toarray(), columns= vectorizer.get_feature_names_out())\n",
    "df2 = pd.DataFrame(X2.toarray(), columns= vectorizer2.get_feature_names_out())\n",
    "df3 = pd.DataFrame(X3.toarray(),columns=vectorizer3.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['words_with_digits'] = df2.T.sum()\n",
    "df['special_symbols'] = df3.T.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['target'] =  (df['spam'] > 0).apply(int)\n",
    "\n",
    "df = df.drop(['spam', 'ham'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7680"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vectorizer.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создаем транспонированый df\n",
    "df_t = df.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Среднее количество слов в сообщении"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39.163319946452475"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['target'] == 1].T.sum().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.946550652579242"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['target'] == 0].T.sum().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3901, 7680) (1673, 7680) (3901,) (1673,)\n"
     ]
    }
   ],
   "source": [
    "# разделение\n",
    "features = df.drop('target',axis=1)\n",
    "target = df['target']\n",
    "features_train, features_test, target_train, target_test = train_test_split(features,target, test_size=.3, random_state=123456)\n",
    "print(features_train.shape, features_test.shape, target_train.shape, target_test.shape )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train['len_diff'] = abs(df_t.sum() - features_train[target_train == 1].T.sum().mean())\n",
    "features_test['len_diff'] = abs(df_t.sum() - features_train[target_train == 1].T.sum().mean())\n",
    "features['len_diff'] = abs(df_t.sum() - features_train[target_train == 1].T.sum().mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Сбалансированный df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train_ones = features_train[target_train == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train_zeros = features_train[target_train == 0].sample(n=features_train_ones.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train_balanced = pd.concat([features_train_ones, features_train_zeros])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train_balanced = features_train_balanced.join(target_train)\n",
    "features_train_balanced = shuffle(features_train_balanced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_train_balanced = features_train_balanced['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train_balanced = features_train_balanced.drop('target', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Баланс классов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Общий баланс классов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1340150699677072"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['target'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Баланс классов train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.12971033068443988"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_train.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_train_balanced.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Баланс классов test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.14405260011954574"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_test.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Поиск важных слов\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "special_symbols      15925\n",
       "words_with_digits     2540\n",
       "target                 747\n",
       "free                   226\n",
       "txt                    166\n",
       "ur                     144\n",
       "mobile                 128\n",
       "stop                   125\n",
       "text                   125\n",
       "claim                  113\n",
       "reply                  104\n",
       "www                     98\n",
       "prize                   93\n",
       "just                    79\n",
       "cash                    76\n",
       "won                     76\n",
       "uk                      74\n",
       "send                    71\n",
       "new                     69\n",
       "nokia                   67\n",
       "win                     64\n",
       "urgent                  63\n",
       "week                    60\n",
       "tone                    60\n",
       "service                 56\n",
       "dtype: int64"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['target'] == 1].sum().sort_values(ascending=False)[:25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "special_symbols      18803\n",
       "words_with_digits      356\n",
       "gt                     318\n",
       "lt                     316\n",
       "just                   297\n",
       "ok                     288\n",
       "ll                     266\n",
       "ur                     247\n",
       "know                   237\n",
       "good                   235\n",
       "got                    234\n",
       "like                   234\n",
       "come                   230\n",
       "day                    217\n",
       "love                   205\n",
       "time                   202\n",
       "going                  169\n",
       "home                   165\n",
       "want                   165\n",
       "lor                    162\n",
       "don                    159\n",
       "need                   159\n",
       "sorry                  157\n",
       "da                     150\n",
       "today                  139\n",
       "dtype: int64"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['target'] == 0].sum().sort_values(ascending=False)[:25]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Вывод:** Можно утверждать, что в spam-сообщениях часто употребляются такие слова как free и txt, а также есть много слов с цифрами"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnb = ComplementNB()\n",
    "cnb_bal = ComplementNB()\n",
    "lgr = LogisticRegression(max_iter=2000)\n",
    "cbc = CatBoostClassifier(verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoring = ['f1']\n",
    "def make_cv2(model_name, model_, cv, scoring,features_train, target_train):\n",
    "    scores = cross_validate(model_, features_train, target_train, cv=cv, scoring=scoring)\n",
    "    print(model_name)\n",
    "    print(f'mean=',scores['test_f1'].mean())\n",
    "    print(f'std=',scores['test_f1'].std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NB not balanced\n",
      "mean= 0.8479433295125964\n",
      "std= 0.038820387690466834\n",
      "NB balanced\n",
      "mean= 0.9405555840520545\n",
      "std= 0.02080961306435698\n",
      "log_reg_balanced\n",
      "mean= 0.9659671262224336\n",
      "std= 0.009829848014354842\n",
      "catboost\n",
      "mean= 0.9553725768770907\n",
      "std= 0.00924145948723892\n"
     ]
    }
   ],
   "source": [
    "make_cv2('NB not balanced', cnb, 5, scoring, features_train, target_train)\n",
    "make_cv2('NB balanced', cnb_bal, 5, scoring, features_train_balanced, target_train_balanced)\n",
    "make_cv2('log_reg_balanced', lgr, 5, scoring, features_train_balanced, target_train_balanced)\n",
    "make_cv2('catboost', cbc, 5, scoring, features_train_balanced, target_train_balanced)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x12fd11550>"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnb.fit(features_train,target_train)\n",
    "cnb_bal.fit(features_train_balanced, target_train_balanced)\n",
    "lgr.fit(features_train_balanced, target_train_balanced)\n",
    "cbc.fit(features_train_balanced, target_train_balanced, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_model_rep(model_kind, model, features_train, target_train, features_test, target_test):\n",
    "    print(model_kind)\n",
    "    print('train')\n",
    "    prediction = model.predict(features_train)\n",
    "    print(classification_report(target_train, prediction))\n",
    "    print('test')\n",
    "    prediction = model.predict(features_test)\n",
    "    print(classification_report(target_test, prediction))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NB not balanced\n",
      "train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.97      0.98      3395\n",
      "           1       0.84      0.93      0.88       506\n",
      "\n",
      "    accuracy                           0.97      3901\n",
      "   macro avg       0.91      0.95      0.93      3901\n",
      "weighted avg       0.97      0.97      0.97      3901\n",
      "\n",
      "test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.98      1432\n",
      "           1       0.93      0.86      0.89       241\n",
      "\n",
      "    accuracy                           0.97      1673\n",
      "   macro avg       0.95      0.93      0.94      1673\n",
      "weighted avg       0.97      0.97      0.97      1673\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_model_rep('NB not balanced', cnb, features_train, target_train, features_test, target_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NB balanced\n",
      "train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.97      0.96       506\n",
      "           1       0.97      0.94      0.96       506\n",
      "\n",
      "    accuracy                           0.96      1012\n",
      "   macro avg       0.96      0.96      0.96      1012\n",
      "weighted avg       0.96      0.96      0.96      1012\n",
      "\n",
      "test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.98      1432\n",
      "           1       0.92      0.86      0.89       241\n",
      "\n",
      "    accuracy                           0.97      1673\n",
      "   macro avg       0.95      0.92      0.94      1673\n",
      "weighted avg       0.97      0.97      0.97      1673\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_model_rep('NB balanced', cnb_bal, features_train_balanced, target_train_balanced, features_test, target_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_reg_balanced\n",
      "train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00       506\n",
      "           1       1.00      0.99      1.00       506\n",
      "\n",
      "    accuracy                           1.00      1012\n",
      "   macro avg       1.00      1.00      1.00      1012\n",
      "weighted avg       1.00      1.00      1.00      1012\n",
      "\n",
      "test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.99      1432\n",
      "           1       0.96      0.90      0.93       241\n",
      "\n",
      "    accuracy                           0.98      1673\n",
      "   macro avg       0.97      0.95      0.96      1673\n",
      "weighted avg       0.98      0.98      0.98      1673\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_model_rep('log_reg_balanced', lgr, features_train_balanced, target_train_balanced, features_test, target_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "catboost\n",
      "train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       506\n",
      "           1       1.00      1.00      1.00       506\n",
      "\n",
      "    accuracy                           1.00      1012\n",
      "   macro avg       1.00      1.00      1.00      1012\n",
      "weighted avg       1.00      1.00      1.00      1012\n",
      "\n",
      "test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.98      1432\n",
      "           1       0.88      0.93      0.90       241\n",
      "\n",
      "    accuracy                           0.97      1673\n",
      "   macro avg       0.94      0.95      0.94      1673\n",
      "weighted avg       0.97      0.97      0.97      1673\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_model_rep('catboost', cbc, features_train_balanced, target_train_balanced, features_test, target_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Кросс-валидация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kf = KFold(n_splits=5)\n",
    "kf.get_n_splits()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cv_values(model_kind, model, features, target, kf ):\n",
    "    num_fold = 0\n",
    "    for train_index, test_index in kf.split(features):\n",
    "        num_fold += 1\n",
    "        print(f'Fold number {num_fold}')\n",
    "        print_model_rep(model_kind, model, features.loc[train_index], target[train_index], features.loc[test_index], target[test_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold number 1\n",
      "NB not balanced\n",
      "train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98      3880\n",
      "           1       0.89      0.88      0.88       579\n",
      "\n",
      "    accuracy                           0.97      4459\n",
      "   macro avg       0.93      0.93      0.93      4459\n",
      "weighted avg       0.97      0.97      0.97      4459\n",
      "\n",
      "test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.99       947\n",
      "           1       0.94      0.90      0.92       168\n",
      "\n",
      "    accuracy                           0.98      1115\n",
      "   macro avg       0.96      0.94      0.95      1115\n",
      "weighted avg       0.98      0.98      0.98      1115\n",
      "\n",
      "Fold number 2\n",
      "NB not balanced\n",
      "train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.98      3853\n",
      "           1       0.91      0.88      0.89       606\n",
      "\n",
      "    accuracy                           0.97      4459\n",
      "   macro avg       0.94      0.93      0.94      4459\n",
      "weighted avg       0.97      0.97      0.97      4459\n",
      "\n",
      "test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98       974\n",
      "           1       0.86      0.89      0.87       141\n",
      "\n",
      "    accuracy                           0.97      1115\n",
      "   macro avg       0.92      0.93      0.93      1115\n",
      "weighted avg       0.97      0.97      0.97      1115\n",
      "\n",
      "Fold number 3\n",
      "NB not balanced\n",
      "train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98      3849\n",
      "           1       0.90      0.89      0.90       610\n",
      "\n",
      "    accuracy                           0.97      4459\n",
      "   macro avg       0.94      0.94      0.94      4459\n",
      "weighted avg       0.97      0.97      0.97      4459\n",
      "\n",
      "test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98       978\n",
      "           1       0.88      0.85      0.87       137\n",
      "\n",
      "    accuracy                           0.97      1115\n",
      "   macro avg       0.93      0.92      0.92      1115\n",
      "weighted avg       0.97      0.97      0.97      1115\n",
      "\n",
      "Fold number 4\n",
      "NB not balanced\n",
      "train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98      3868\n",
      "           1       0.90      0.89      0.89       591\n",
      "\n",
      "    accuracy                           0.97      4459\n",
      "   macro avg       0.94      0.94      0.94      4459\n",
      "weighted avg       0.97      0.97      0.97      4459\n",
      "\n",
      "test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98       959\n",
      "           1       0.90      0.86      0.88       156\n",
      "\n",
      "    accuracy                           0.97      1115\n",
      "   macro avg       0.94      0.92      0.93      1115\n",
      "weighted avg       0.97      0.97      0.97      1115\n",
      "\n",
      "Fold number 5\n",
      "NB not balanced\n",
      "train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98      3858\n",
      "           1       0.90      0.88      0.89       602\n",
      "\n",
      "    accuracy                           0.97      4460\n",
      "   macro avg       0.94      0.93      0.93      4460\n",
      "weighted avg       0.97      0.97      0.97      4460\n",
      "\n",
      "test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       969\n",
      "           1       0.90      0.91      0.91       145\n",
      "\n",
      "    accuracy                           0.98      1114\n",
      "   macro avg       0.95      0.95      0.95      1114\n",
      "weighted avg       0.98      0.98      0.98      1114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "get_cv_values('NB not balanced', cnb, features, target, kf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold number 1\n",
      "NB balanced\n",
      "train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98      3880\n",
      "           1       0.88      0.88      0.88       579\n",
      "\n",
      "    accuracy                           0.97      4459\n",
      "   macro avg       0.93      0.93      0.93      4459\n",
      "weighted avg       0.97      0.97      0.97      4459\n",
      "\n",
      "test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.99       947\n",
      "           1       0.94      0.89      0.92       168\n",
      "\n",
      "    accuracy                           0.98      1115\n",
      "   macro avg       0.96      0.94      0.95      1115\n",
      "weighted avg       0.98      0.98      0.98      1115\n",
      "\n",
      "Fold number 2\n",
      "NB balanced\n",
      "train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98      3853\n",
      "           1       0.90      0.88      0.89       606\n",
      "\n",
      "    accuracy                           0.97      4459\n",
      "   macro avg       0.94      0.93      0.94      4459\n",
      "weighted avg       0.97      0.97      0.97      4459\n",
      "\n",
      "test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.98       974\n",
      "           1       0.86      0.91      0.89       141\n",
      "\n",
      "    accuracy                           0.97      1115\n",
      "   macro avg       0.93      0.94      0.93      1115\n",
      "weighted avg       0.97      0.97      0.97      1115\n",
      "\n",
      "Fold number 3\n",
      "NB balanced\n",
      "train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98      3849\n",
      "           1       0.90      0.89      0.89       610\n",
      "\n",
      "    accuracy                           0.97      4459\n",
      "   macro avg       0.94      0.94      0.94      4459\n",
      "weighted avg       0.97      0.97      0.97      4459\n",
      "\n",
      "test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98       978\n",
      "           1       0.86      0.85      0.85       137\n",
      "\n",
      "    accuracy                           0.96      1115\n",
      "   macro avg       0.92      0.91      0.92      1115\n",
      "weighted avg       0.96      0.96      0.96      1115\n",
      "\n",
      "Fold number 4\n",
      "NB balanced\n",
      "train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98      3868\n",
      "           1       0.89      0.89      0.89       591\n",
      "\n",
      "    accuracy                           0.97      4459\n",
      "   macro avg       0.94      0.94      0.94      4459\n",
      "weighted avg       0.97      0.97      0.97      4459\n",
      "\n",
      "test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98       959\n",
      "           1       0.90      0.87      0.88       156\n",
      "\n",
      "    accuracy                           0.97      1115\n",
      "   macro avg       0.94      0.92      0.93      1115\n",
      "weighted avg       0.97      0.97      0.97      1115\n",
      "\n",
      "Fold number 5\n",
      "NB balanced\n",
      "train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98      3858\n",
      "           1       0.89      0.88      0.89       602\n",
      "\n",
      "    accuracy                           0.97      4460\n",
      "   macro avg       0.94      0.93      0.93      4460\n",
      "weighted avg       0.97      0.97      0.97      4460\n",
      "\n",
      "test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.98       969\n",
      "           1       0.87      0.91      0.89       145\n",
      "\n",
      "    accuracy                           0.97      1114\n",
      "   macro avg       0.93      0.95      0.94      1114\n",
      "weighted avg       0.97      0.97      0.97      1114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "get_cv_values('NB balanced', cnb_bal, features, target, kf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold number 1\n",
      "log_reg_balanced\n",
      "train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      3880\n",
      "           1       0.95      0.93      0.94       579\n",
      "\n",
      "    accuracy                           0.98      4459\n",
      "   macro avg       0.97      0.96      0.97      4459\n",
      "weighted avg       0.98      0.98      0.98      4459\n",
      "\n",
      "test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       947\n",
      "           1       0.97      0.94      0.95       168\n",
      "\n",
      "    accuracy                           0.99      1115\n",
      "   macro avg       0.98      0.97      0.97      1115\n",
      "weighted avg       0.99      0.99      0.99      1115\n",
      "\n",
      "Fold number 2\n",
      "log_reg_balanced\n",
      "train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      3853\n",
      "           1       0.96      0.93      0.94       606\n",
      "\n",
      "    accuracy                           0.98      4459\n",
      "   macro avg       0.97      0.96      0.97      4459\n",
      "weighted avg       0.98      0.98      0.98      4459\n",
      "\n",
      "test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       974\n",
      "           1       0.93      0.95      0.94       141\n",
      "\n",
      "    accuracy                           0.98      1115\n",
      "   macro avg       0.96      0.97      0.97      1115\n",
      "weighted avg       0.98      0.98      0.98      1115\n",
      "\n",
      "Fold number 3\n",
      "log_reg_balanced\n",
      "train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      3849\n",
      "           1       0.95      0.94      0.95       610\n",
      "\n",
      "    accuracy                           0.99      4459\n",
      "   macro avg       0.97      0.97      0.97      4459\n",
      "weighted avg       0.99      0.99      0.99      4459\n",
      "\n",
      "test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       978\n",
      "           1       0.96      0.91      0.93       137\n",
      "\n",
      "    accuracy                           0.98      1115\n",
      "   macro avg       0.97      0.95      0.96      1115\n",
      "weighted avg       0.98      0.98      0.98      1115\n",
      "\n",
      "Fold number 4\n",
      "log_reg_balanced\n",
      "train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      3868\n",
      "           1       0.96      0.94      0.95       591\n",
      "\n",
      "    accuracy                           0.99      4459\n",
      "   macro avg       0.97      0.96      0.97      4459\n",
      "weighted avg       0.99      0.99      0.99      4459\n",
      "\n",
      "test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       959\n",
      "           1       0.95      0.92      0.93       156\n",
      "\n",
      "    accuracy                           0.98      1115\n",
      "   macro avg       0.97      0.95      0.96      1115\n",
      "weighted avg       0.98      0.98      0.98      1115\n",
      "\n",
      "Fold number 5\n",
      "log_reg_balanced\n",
      "train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      3858\n",
      "           1       0.95      0.93      0.94       602\n",
      "\n",
      "    accuracy                           0.98      4460\n",
      "   macro avg       0.97      0.96      0.97      4460\n",
      "weighted avg       0.98      0.98      0.98      4460\n",
      "\n",
      "test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       969\n",
      "           1       0.96      0.94      0.95       145\n",
      "\n",
      "    accuracy                           0.99      1114\n",
      "   macro avg       0.97      0.97      0.97      1114\n",
      "weighted avg       0.99      0.99      0.99      1114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "get_cv_values('log_reg_balanced', lgr, features, target, kf)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold number 1\n",
      "catboost\n",
      "train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.98      3880\n",
      "           1       0.86      0.94      0.90       579\n",
      "\n",
      "    accuracy                           0.97      4459\n",
      "   macro avg       0.93      0.96      0.94      4459\n",
      "weighted avg       0.97      0.97      0.97      4459\n",
      "\n",
      "test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       947\n",
      "           1       0.92      0.95      0.94       168\n",
      "\n",
      "    accuracy                           0.98      1115\n",
      "   macro avg       0.96      0.97      0.96      1115\n",
      "weighted avg       0.98      0.98      0.98      1115\n",
      "\n",
      "Fold number 2\n",
      "catboost\n",
      "train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.99      3853\n",
      "           1       0.89      0.94      0.91       606\n",
      "\n",
      "    accuracy                           0.98      4459\n",
      "   macro avg       0.94      0.96      0.95      4459\n",
      "weighted avg       0.98      0.98      0.98      4459\n",
      "\n",
      "test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.97      0.98       974\n",
      "           1       0.84      0.97      0.90       141\n",
      "\n",
      "    accuracy                           0.97      1115\n",
      "   macro avg       0.92      0.97      0.94      1115\n",
      "weighted avg       0.98      0.97      0.97      1115\n",
      "\n",
      "Fold number 3\n",
      "catboost\n",
      "train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.99      3849\n",
      "           1       0.88      0.95      0.91       610\n",
      "\n",
      "    accuracy                           0.98      4459\n",
      "   macro avg       0.94      0.96      0.95      4459\n",
      "weighted avg       0.98      0.98      0.98      4459\n",
      "\n",
      "test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.98       978\n",
      "           1       0.86      0.92      0.89       137\n",
      "\n",
      "    accuracy                           0.97      1115\n",
      "   macro avg       0.92      0.95      0.94      1115\n",
      "weighted avg       0.97      0.97      0.97      1115\n",
      "\n",
      "Fold number 4\n",
      "catboost\n",
      "train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.99      3868\n",
      "           1       0.88      0.95      0.91       591\n",
      "\n",
      "    accuracy                           0.98      4459\n",
      "   macro avg       0.93      0.96      0.95      4459\n",
      "weighted avg       0.98      0.98      0.98      4459\n",
      "\n",
      "test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.98       959\n",
      "           1       0.88      0.93      0.91       156\n",
      "\n",
      "    accuracy                           0.97      1115\n",
      "   macro avg       0.94      0.95      0.95      1115\n",
      "weighted avg       0.97      0.97      0.97      1115\n",
      "\n",
      "Fold number 5\n",
      "catboost\n",
      "train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.99      3858\n",
      "           1       0.88      0.94      0.91       602\n",
      "\n",
      "    accuracy                           0.97      4460\n",
      "   macro avg       0.93      0.96      0.95      4460\n",
      "weighted avg       0.98      0.97      0.97      4460\n",
      "\n",
      "test\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.99       969\n",
      "           1       0.87      0.95      0.91       145\n",
      "\n",
      "    accuracy                           0.98      1114\n",
      "   macro avg       0.93      0.97      0.95      1114\n",
      "weighted avg       0.98      0.98      0.98      1114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "get_cv_values('catboost', cbc, features, target, kf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Гипотеза о равенстве средних"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = []\n",
    "for _ in range(50):\n",
    "    samples.append(features.sample(n=100,replace=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_f1(model, samples):\n",
    "    f1_lst = []\n",
    "    for elem in samples:\n",
    "        elem_features = elem\n",
    "        elem_target = target[elem_features.index]\n",
    "        prediction = model.predict(elem_features)\n",
    "        f1_lst.append(f1_score(elem_target, prediction))\n",
    "    return f1_lst\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conf_int(f1_lst):\n",
    "    f1_lst = pd.Series(f1_lst)\n",
    "    print(f1_lst.mean())\n",
    "    mean_f1 = f1_lst.mean()\n",
    "    t_low = f1_lst.quantile(.005)\n",
    "    t_high = f1_lst.quantile(.995)\n",
    "    sem_mean = f1_lst.sem()\n",
    "    return mean_f1 + t_low * sem_mean, mean_f1 + t_high * sem_mean\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Доверительный интервал"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8910154542274433\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.8977830324341752, 0.9012541443371611)"
      ]
     },
     "execution_count": 335,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conf_int(get_f1(cnb, samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8904058136425063\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.8974058285469362, 0.9004529503894804)"
      ]
     },
     "execution_count": 336,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conf_int(get_f1(cnb_bal, samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9446564774860431\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.9506309098578992, 0.9520370227768512)"
      ]
     },
     "execution_count": 337,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conf_int(get_f1(lgr, samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.904904041462919\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.9111343904195075, 0.9135035569309501)"
      ]
     },
     "execution_count": 338,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conf_int(get_f1(cbc, samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ttest_indResult(statistic=0.042498812335333994, pvalue=0.9661875582755408)\n"
     ]
    }
   ],
   "source": [
    "print(ttest_ind(get_f1(cnb, samples),get_f1(cnb_bal, samples),equal_var=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ttest_indResult(statistic=-4.3516627379775175, pvalue=3.561377093917459e-05)\n"
     ]
    }
   ],
   "source": [
    "print(ttest_ind(get_f1(cnb_bal, samples),get_f1(lgr, samples),equal_var=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ttest_indResult(statistic=-1.0962868574893463, pvalue=0.2757037732272059)\n"
     ]
    }
   ],
   "source": [
    "print(ttest_ind(get_f1(cnb_bal, samples),get_f1(cbc, samples),equal_var=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Вывод** нам удалось сделать модель, которая в некоторой степени умеет классифицировать сообщения на SPAM и HAM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
